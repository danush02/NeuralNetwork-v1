{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class NeuralNetwork2:\n",
    "    def __init__(self, max_iter=1000, alpha = 0.001) -> None:\n",
    "        self.W = 0\n",
    "        self.b = np.float32(random.random())\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.n_features = 0\n",
    "        self.grad_W = 0\n",
    "        self.grad_b = 0\n",
    "\n",
    "    def preactivation(self, X):\n",
    "        val = np.dot(self.W,X) + self.b\n",
    "        return np.array(val)\n",
    "\n",
    "    def sigmoid(self,val):\n",
    "        sig_val = np.divide(1,(np.add(1,np.exp(-val))))\n",
    "        return sig_val\n",
    "\n",
    "    def model_out(self, sig_val):\n",
    "        out = np.where(sig_val > 0.5, 1, 0)\n",
    "        return out\n",
    "\n",
    "    def calc_loss(self, y, sig_val):\n",
    "        error = np.subtract(sig_val,y)\n",
    "        loss = np.sum(np.square(error))\n",
    "        return loss\n",
    "\n",
    "    def calc_gradient(self, y, sig_val, X):\n",
    "        error = np.subtract(sig_val,y)\n",
    "        self.grad_W = np.dot(X, error) / len(y)\n",
    "        self.grad_b = np.mean(error)\n",
    "\n",
    "    def update_weights(self):\n",
    "        self.W -= self.alpha * self.grad_W\n",
    "        self.b -= self.alpha * self.grad_b\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X).T\n",
    "        y = np.array(y).T\n",
    "        self.n_features = len(X)\n",
    "        self.W = np.random.rand(self.n_features)\n",
    "        self.grad_W = np.zeros_like(self.W)\n",
    "        for i in range(self.max_iter+1):\n",
    "            sig_val = self.sigmoid(self.preactivation(X))\n",
    "            loss_val = self.calc_loss(y,sig_val)\n",
    "            if i%10000 == 0:\n",
    "                print(f\"Loss Value: {np.mean(loss_val)}, Iteration: {i}\")\n",
    "                print(f\"Weights: {self.W}\")\n",
    "                print(f\"Gradient: {self.grad_W}, Bias: {self.grad_b}\")\n",
    "            self.calc_gradient(y, sig_val, X)\n",
    "            self.update_weights()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X).T\n",
    "        return self.model_out(self.sigmoid(self.preactivation(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:/Learn ML/Dataset/Iris.csv\")\n",
    "target_map = {\"Iris-setosa\":0, \"Iris-versicolor\":1}\n",
    "df['Species'] = df['Species'].map(target_map)\n",
    "df.head()\n",
    "df.drop(\"Id\",axis=1)\n",
    "nn = NeuralNetwork2(max_iter=60000,alpha=0.05)\n",
    "taget_col = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "feature_df = df[taget_col]\n",
    "target_df = df['Species']\n",
    "print(len(feature_df.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value: 35.95141393748536, Iteration: 0\n",
      "Weights: [0.53976626 0.00536354 0.09430555 0.18505311]\n",
      "Gradient: [0. 0. 0. 0.], Bias: 0\n",
      "Loss Value: 0.001361062063410965, Iteration: 10000\n",
      "Weights: [-0.7082748  -2.92980373  4.09752715  2.04067881]\n",
      "Gradient: [ 0.00028246  0.00087221 -0.00143575 -0.00070161], Bias: 0.00017580650612450174\n",
      "Loss Value: 0.0004996113779002734, Iteration: 20000\n",
      "Weights: [-0.8086073  -3.23441579  4.60325194  2.2902889 ]\n",
      "Gradient: [ 0.00014856  0.00044281 -0.00074183 -0.00036973], Bias: 9.057204892852052e-05\n",
      "Loss Value: 0.00027541950385628753, Iteration: 30000\n",
      "Weights: [-0.86985358 -3.41471371  4.90707422  2.4425677 ]\n",
      "Gradient: [ 0.00010243  0.00029767 -0.00050464 -0.00025433], Bias: 6.166713192632047e-05\n",
      "Loss Value: 0.00017956085569006546, Iteration: 40000\n",
      "Weights: [-0.91461671 -3.54351923  5.12642705  2.55354147]\n",
      "Gradient: [ 7.88022780e-05  2.24473979e-04 -3.84041063e-04 -1.95025242e-04], Bias: 4.7018773468785686e-05\n",
      "Loss Value: 0.00012843163089085866, Iteration: 50000\n",
      "Weights: [-0.9501459  -3.64389676  5.29879864  2.64132753]\n",
      "Gradient: [ 6.43474909e-05  1.80283460e-04 -3.10758904e-04 -1.58712219e-04], Bias: 3.812981595638831e-05\n",
      "Loss Value: 9.744831705957169e-05, Iteration: 60000\n",
      "Weights: [-0.97972798 -3.72619349  5.44110678  2.71417296]\n",
      "Gradient: [ 5.45519896e-05  1.50682860e-04 -2.61398976e-04 -1.34106030e-04], Bias: 3.214531976907111e-05\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_df, target_df, test_size=0.2, random_state=42)\n",
    "nn.fit(X=X_train,y=y_train)\n",
    "y_out = nn.predict(X=X_test)\n",
    "print(accuracy_score(y_test,y_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
